{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c35161",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "- % alts w/ uncorrected samp. prob > pop. mean prob: should decrease as $N_s$ --> $N_p$\n",
    "- avg. (max corrected samp. prob - true max prob): should approach zero as $N_s$ --> $N_p$\n",
    "\n",
    "#### Notes\n",
    "- bias of naive correction factor estimator seems very related to \"spikey-ness\" of distribution. but mean abs err does not!\n",
    "- probability distribution seems to get less spikey with more parameters\n",
    "- Spikey-ness is a function of model error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc426267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import jax\n",
    "import jaxlib\n",
    "from jax import grad, jit, vmap, remat, lax\n",
    "import jax.numpy as np\n",
    "import jax.random as random\n",
    "from jax.experimental import optimizers\n",
    "from jax.ops import index, index_update\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7dd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d521265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5344ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(u, scale=1, corr_factor=1):\n",
    "    \"\"\" \n",
    "    Probability equation for multinomial logit. \n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    u: array-like. Array containing the utility estimate for each alternative. \n",
    "    scale: (int, optional ) - Scaling factor for exp(scale * u). Default = 1 \n",
    "    axis: (None or int or tuple of ints, optional) – Axis or axes over which the sum is taken. By default axis is None, and all elements are summed.\n",
    "\n",
    "    Returns: \n",
    "    ----------\n",
    "    (array) Probabilites for each alternative\n",
    "    \"\"\"\n",
    "    exp_utility = np.exp(scale * u)\n",
    "    sum_exp_utility = np.sum(exp_utility * corr_factor, keepdims=True)\n",
    "    proba = exp_utility / sum_exp_utility\n",
    "    return proba\n",
    "\n",
    "def logsums(u, scale=1, axis=1, corr_factor=1):\n",
    "    \"\"\" \n",
    "    Maximum expected utility \n",
    "    Parameters:\n",
    "    ------------\n",
    "    u: array-like. Array containing the unscaled utility estimate for each alternative. \n",
    "    scale: (int, optional ) - Scaling factor for exp(scale * u). Default = 1 \n",
    "    axis: (None or int or tuple of ints, optional) – Axis or axes over which the sum is taken. By default axis is None, and all elements are summed.\n",
    "\n",
    "    return: \n",
    "    -------\n",
    "    Maximum expected utility of the nest\n",
    "    \"\"\"\n",
    "    return (1 / scale) * np.log(np.sum(np.exp(scale * u) * corr_factor, axis=axis))\n",
    "\n",
    "class large_mnl():\n",
    "    \"\"\"\n",
    "    Differentiable approach for multinomial logit with large alternative set \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_object=None, coeffs=None, n_choosers=None, n_alts=None):\n",
    "        self.weights = coeffs\n",
    "        self.n_choosers = n_choosers\n",
    "        self.n_alts = n_alts\n",
    "        # self.constrains  = constrains \n",
    "        ## TO DO: yaml file\n",
    "            \n",
    "    def utilities(self, x):\n",
    "        \"\"\" Calculates the utility fuction of weights w and data x \n",
    "        Parameters:\n",
    "        ------------\n",
    "        x = Jax 2d array, OrcaTable wrapper name, Pandas DataFrame. Column names must match coefficient names.\n",
    "            if a Jax array, order of columns should be the same order as the coeffient names. \n",
    "\n",
    "        Return:\n",
    "        ------------\n",
    "        2-d jax numpy array with utilities for eahc alternative.\n",
    "        \"\"\"\n",
    "\n",
    "        w = self.weights\n",
    "        n = self.n_choosers\n",
    "        j = self.n_alts\n",
    "        return np.dot(x, w.T).reshape(n,j)\n",
    "\n",
    "    def probabilities(self, x, scale=1, corr_factor=1):\n",
    "        ''' Estimates the probabilities for each alternative in the choice set for each individual '''\n",
    "        utils = self.utilities(x)\n",
    "        return vmap(softmax, in_axes=(0, None, None))(utils, scale, corr_factor)\n",
    "\n",
    "    def logsum(self, x):\n",
    "        ''' Estimates the maximum expected utility for all alternatives in the choice set\n",
    "            Scale parameter normalized to 1. \n",
    "        '''\n",
    "        utils = self.utilities(x)\n",
    "        return vmap(logsums)(utils)\n",
    "\n",
    "    def simulation(self, x, key):\n",
    "        ''' \n",
    "        Monte Carlo simulation. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x: 2-d Jax numpy array\n",
    "        key: jax PRNG Key object\n",
    "        \n",
    "        Return\n",
    "        -------\n",
    "        - numpy.array \n",
    "\n",
    "        '''\n",
    "        utils = self.utilities(x)\n",
    "        shape = utils.shape\n",
    "        keys = random.split(key, shape[0])\n",
    "\n",
    "        @jit\n",
    "        def single_simulation(u, key):\n",
    "            return random.categorical(key, u)\n",
    "\n",
    "        choices = vmap(single_simulation, in_axes=(0, 0))(utils, keys)\n",
    "        return choices  ### Assuming alternative name starts at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4336577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mct(choosers, alts, var_mats=None, chooser_alts=None):\n",
    "    \n",
    "    num_choosers = choosers.shape[0]\n",
    "    num_alts = alts.shape[0]\n",
    "    sample_size = chooser_alts.shape[1]\n",
    "    \n",
    "    if chooser_alts is None:\n",
    "        mct = np.tile(alts, (num_choosers, 1))\n",
    "        mct = np.hstack((mct, choosers.repeat(num_alts)))\n",
    "    else:\n",
    "        mct = np.vstack([alts[chooser_alts[i, :], :] for i in range(num_choosers)])\n",
    "        mct = np.hstack((mct, choosers.repeat(sample_size).reshape(-1, 1)))\n",
    "    \n",
    "    return mct\n",
    "\n",
    "def create_data(num_alts, pop_to_alts_ratio, num_vars=5):\n",
    "    \n",
    "    # create choosers\n",
    "    n_choosers = int(pop_to_alts_ratio * num_alts)\n",
    "    choosers = onp.random.lognormal(0, 0.5, n_choosers)  # 1 chooser attribute\n",
    "    \n",
    "    # initialize alts\n",
    "    alts = onp.zeros((num_alts, num_vars))\n",
    "    \n",
    "    # dist to CBD\n",
    "    alts[:, 0] = onp.random.lognormal(0, 1, num_alts)  # Dist to CBD\n",
    "    \n",
    "    # size terms\n",
    "    for i in range(1, num_vars - 1):\n",
    "        split_val = int(onp.floor(num_alts * .5))\n",
    "        alts[:split_val, i] = onp.random.normal(1, 1, split_val)  # first 1/2 of alts have mean = 1\n",
    "        alts[split_val:, i] = onp.random.normal(0.5, 1, num_alts - split_val)  # rest of alts have mean 0.5\n",
    "    \n",
    "    # interaction term\n",
    "    alts[:, -1] = onp.random.lognormal(1, .5, num_alts)\n",
    "    \n",
    "    return np.array(choosers), np.array(alts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d48995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jit, static_argnums=[3])\n",
    "def interaction(chooser_val, key, alts, sample_size):\n",
    "\n",
    "    total_alts = alts.shape[0]\n",
    "    sample_rate = sample_size / total_alts\n",
    "    \n",
    "    alts_idxs = np.array(range(total_alts))\n",
    "    shuffled_idxs = random.permutation(key, alts_idxs)\n",
    "    if sample_size < total_alts:\n",
    "        alts_idxs = alts_idxs[shuffled_idxs[:sample_size]]\n",
    "\n",
    "    alts = alts[alts_idxs, :]\n",
    "    \n",
    "    idx_alt_intx = -1\n",
    "    coeffs = np.array([-1, 1, 1, 1, 1])\n",
    "    interacted = alts[:, idx_alt_intx] / chooser_val\n",
    "    alts2 = alts.at[:, idx_alt_intx].set(interacted)\n",
    "    \n",
    "    logits = np.dot(alts2, coeffs.T)\n",
    "    probas = softmax(logits)\n",
    "    probas = probas.flatten()\n",
    "    \n",
    "    pop_mean_prob = 1 / num_alts\n",
    "    pct_probs_gt_pop_mean = np.sum(probas > pop_mean_prob) / sample_size\n",
    "    \n",
    "    max_prob = np.nanmax(probas)\n",
    "    \n",
    "    return max_prob, pct_probs_gt_pop_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72aaf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(choosers, alts, key, sample_size):\n",
    "    \"\"\"VMAP the interaction function over all choosers' values\"\"\"\n",
    "    num_choosers = choosers.shape[0]\n",
    "    keys = random.split(key, num_choosers)\n",
    "    probas_all = vmap(interaction, in_axes=(0, 0, None, None))(choosers, keys, alts, sample_size)\n",
    "    return probas_all\n",
    "\n",
    "def get_probs_batched(choosers, alts, key, sample_size):\n",
    "    \"\"\"VMAP the interaction function over all choosers' values\"\"\"\n",
    "\n",
    "    num_choosers = choosers.shape[0]\n",
    "    num_alts = alts.shape[0]\n",
    "    \n",
    "    n_chooser_batches = 1\n",
    "    if num_choosers * num_alts > 750000000:\n",
    "        while True:\n",
    "            n_chooser_batches += 1\n",
    "            if num_choosers % n_chooser_batches != 0:\n",
    "                continue\n",
    "            elif (num_choosers / n_chooser_batches) * num_alts < 750000000:\n",
    "                break\n",
    "        choosers = choosers.reshape((n_chooser_batches, int(num_choosers / n_chooser_batches)))\n",
    "    \n",
    "    keys = random.split(key, num_choosers)\n",
    "    probas_all = lax.map(vmap(interaction, in_axes=(0, 0, None, None)), (choosers, keys, alts, sample_size))\n",
    "\n",
    "    return probas_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad2d2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_to_alts_ratio = 750 / 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d36005b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alts_sizes = [200, 2000, 2e4, 2e5, 2e6]\n",
    "sample_rates = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "coeffs = np.array([-1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "024b5d69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200  ALTS,  750  CHOOSERS\n",
      "Took 1.0 s to compute true probs.\n",
      "Took 0.0 s to compute true prob. metrics\n",
      "Took 0.0 s to compute 10.0% sample probs.\n",
      "Took 0.0 s to compute 10.0% sample metrics.\n",
      "Took 0.0 s to compute 20.0% sample probs.\n",
      "Took 0.0 s to compute 20.0% sample metrics.\n",
      "Took 0.0 s to compute 30.0% sample probs.\n",
      "Took 0.0 s to compute 30.0% sample metrics.\n",
      "Took 0.0 s to compute 40.0% sample probs.\n",
      "Took 0.0 s to compute 40.0% sample metrics.\n",
      "Took 0.0 s to compute 50.0% sample probs.\n",
      "Took 0.0 s to compute 50.0% sample metrics.\n",
      "Took 0.0 s to compute 60.0% sample probs.\n",
      "Took 0.0 s to compute 60.0% sample metrics.\n",
      "Took 0.0 s to compute 70.0% sample probs.\n",
      "Took 0.0 s to compute 70.0% sample metrics.\n",
      "Took 0.0 s to compute 80.0% sample probs.\n",
      "Took 0.0 s to compute 80.0% sample metrics.\n",
      "Took 0.0 s to compute 90.0% sample probs.\n",
      "Took 0.0 s to compute 90.0% sample metrics.\n",
      "2000  ALTS,  7500  CHOOSERS\n",
      "Took 0.0 s to compute true probs.\n",
      "Took 1.0 s to compute true prob. metrics\n",
      "Took 0.0 s to compute 10.0% sample probs.\n",
      "Took 0.0 s to compute 10.0% sample metrics.\n",
      "Took 0.0 s to compute 20.0% sample probs.\n",
      "Took 0.0 s to compute 20.0% sample metrics.\n",
      "Took 0.0 s to compute 30.0% sample probs.\n",
      "Took 0.0 s to compute 30.0% sample metrics.\n",
      "Took 0.0 s to compute 40.0% sample probs.\n",
      "Took 0.0 s to compute 40.0% sample metrics.\n",
      "Took 0.0 s to compute 50.0% sample probs.\n",
      "Took 0.0 s to compute 50.0% sample metrics.\n",
      "Took 0.0 s to compute 60.0% sample probs.\n",
      "Took 0.0 s to compute 60.0% sample metrics.\n",
      "Took 0.0 s to compute 70.0% sample probs.\n",
      "Took 0.0 s to compute 70.0% sample metrics.\n",
      "Took 0.0 s to compute 80.0% sample probs.\n",
      "Took 0.0 s to compute 80.0% sample metrics.\n",
      "Took 0.0 s to compute 90.0% sample probs.\n",
      "Took 0.0 s to compute 90.0% sample metrics.\n",
      "20000  ALTS,  75000  CHOOSERS\n",
      "Took 0.0 s to compute true probs.\n",
      "Took 1.0 s to compute true prob. metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-02 10:37:10.609561: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:456] Allocator (GPU_0_bfc) ran out of memory trying to allocate 22.35GiB (rounded to 24000001024)requested by op \n",
      "2021-11-02 10:37:10.609948: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:467] *___________________________________________________________________________________________________\n",
      "2021-11-02 10:37:10.610014: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:1955] Execution of replica 0 failed: Resource exhausted: Out of memory while trying to allocate 24000000792 bytes.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Resource exhausted: Out of memory while trying to allocate 24000000792 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4106955/1871283513.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_alts\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mprobs_samp_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_samp_probs_gt_pop_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoosers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mlater\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Took {0} s to compute {1}% sample probs.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlater\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4106955/3897647548.py\u001b[0m in \u001b[0;36mget_probs\u001b[0;34m(choosers, alts, key, sample_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnum_choosers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoosers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_choosers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprobas_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoosers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprobas_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/proba/lib/python3.9/site-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled\u001b[0;34m(compiled, avals, handlers, kept_var_idx, *args)\u001b[0m\n\u001b[1;32m    891\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m           if x is not token and i in kept_var_idx))\n\u001b[0;32m--> 893\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_call_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_partition_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Resource exhausted: Out of memory while trying to allocate 24000000792 bytes."
     ]
    }
   ],
   "source": [
    "n_alts_dict = {}\n",
    "metrics = pd.DataFrame(\n",
    "    columns=[\n",
    "        'num_alts', 'sample_rate', 'med_pct_probs_gt_pop_mean',\n",
    "        'med_max_corr_prob', 'pct_choosers_1_gt_95'])\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "for num_alts in alts_sizes:\n",
    "    \n",
    "    num_alts = int(num_alts)\n",
    "    pop_mean_prob = 1 / num_alts\n",
    "    \n",
    "    choosers, alts = create_data(num_alts, pop_to_alts_ratio)\n",
    "    num_choosers = choosers.shape[0]\n",
    "    print(num_alts, \" ALTS, \", num_choosers, \" CHOOSERS\")\n",
    "    now = time.time()\n",
    "    probs_true_max, pct_true_probs_gt_pop_mean = get_probs(choosers, alts, key, num_alts)\n",
    "    later = time.time()\n",
    "    print(\"Took {0} s to compute true probs.\".format(np.round(later - now)))\n",
    "\n",
    "    now = time.time()\n",
    "    med_pct_probs_gt_pop_mean = np.median(pct_true_probs_gt_pop_mean)\n",
    "    med_max_prob = np.median(probs_true_max)\n",
    "    later = time.time()\n",
    "    print(\"Took {0} s to compute true prob. metrics\".format(np.round(later - now)))\n",
    "    \n",
    "    metrics = pd.concat((metrics, pd.DataFrame([{\n",
    "        'num_alts': num_alts,\n",
    "        'sample_rate': 1,\n",
    "        'med_pct_probs_gt_pop_mean': med_pct_probs_gt_pop_mean,\n",
    "        'med_max_corr_prob': med_max_prob}])))\n",
    "\n",
    "    for sample_rate in sample_rates:\n",
    "        now = time.time()\n",
    "        \n",
    "        sample_size = int(num_alts * sample_rate)\n",
    "        \n",
    "        probs_samp_max, pct_samp_probs_gt_pop_mean = get_probs(choosers, alts, key, sample_size)\n",
    "        later = time.time()\n",
    "        print(\"Took {0} s to compute {1}% sample probs.\".format(np.round(later - now), sample_rate * 100))\n",
    "        \n",
    "        # metrics\n",
    "        now = time.time()\n",
    "        med_pct_probs_gt_pop_mean = np.median(pct_samp_probs_gt_pop_mean)\n",
    "        med_max_corr_prob = np.median(probs_samp_max) * sample_rate\n",
    "        later = time.time()\n",
    "        print(\"Took {0} s to compute {1}% sample metrics.\".format(np.round(later - now), sample_rate * 100))\n",
    "\n",
    "        metrics = pd.concat((metrics, pd.DataFrame([{\n",
    "            'num_alts': num_alts,\n",
    "            'sample_rate': sample_rate,\n",
    "            'med_pct_probs_gt_pop_mean': med_pct_probs_gt_pop_mean,\n",
    "            'med_max_corr_prob': med_max_corr_prob}])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75158c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.pointplot(data=metrics, x='sample_rate', y ='med_pct_probs_gt_pop_mean', hue='num_alts', ax=ax)\n",
    "ax.set_title(\"Median % Alts w/ Prob > Pop. Mean Prob\", fontsize=15)\n",
    "ax.set_ylabel(\"Median %\")\n",
    "ax.set_xlabel(\"Sample Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49690354",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.pointplot(data=metrics, x='sample_rate', y ='med_max_corr_prob', hue='num_alts', ax=ax)\n",
    "ax.set_title(\"Median Max. Corrected Prob. Alt\", fontsize=15)\n",
    "ax.set_ylabel(\"Corrected Probability\")\n",
    "ax.set_xlabel(\"Sample Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axarr = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "# for i, (num_alts, n_alts_data) in enumerate(n_alts_dict.items()):\n",
    "#     for sample_size, sample_size_data in n_alts_data.items():\n",
    "#         if sample_size == 1:\n",
    "#             continue\n",
    "#         samp_corr_maxs = sample_size_data['probs_samp_corr'].max(axis=1)\n",
    "#         g = sns.kdeplot(samp_corr_maxs, fill=True,ax=axarr[i], label=str(sample_size))\n",
    "#         polys = [poly for poly in g.get_children() if type(poly) == mpl.collections.PolyCollection]\n",
    "#         color = polys[-1].get_facecolor()\n",
    "#         axarr[i].vlines(onp.nanmedian(samp_corr_maxs), 0, 20, lw=1, color=color, alpha=1, linestyle='--')\n",
    "#     probs_true_max = n_alts_data[1]['probs_true'].max(axis=1)\n",
    "#     g = sns.kdeplot(probs_true_max, fill=True, ax=axarr[i], label=str(1), lw=3)\n",
    "#     polys = [poly for poly in g.get_children() if type(poly) == mpl.collections.PolyCollection]\n",
    "#     color = polys[-1].get_facecolor()\n",
    "#     axarr[i].vlines(onp.nanmedian(probs_true_max), 0, 20, lw=2, color=color, alpha=1)\n",
    "#     axarr[i].legend(title='Sample Rate')\n",
    "#     axarr[i].set_title(\"$N$ = {0}\".format(num_alts), fontsize=15)\n",
    "# fig.suptitle(\"Max. Corrected Probability Across Choosers\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axarr = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "# for i, (num_alts, n_alts_data) in enumerate(n_alts_dict.items()):\n",
    "#     for sample_size, sample_size_data in n_alts_data.items():\n",
    "#         if sample_size == 1:\n",
    "#             continue\n",
    "#         samp_maxs = sample_size_data['probs_true_samp'].max(axis=1)\n",
    "#         g = sns.kdeplot(samp_maxs, fill=True, ax=axarr[i], label=str(sample_size))\n",
    "#         polys = [poly for poly in g.get_children() if type(poly) == mpl.collections.PolyCollection]\n",
    "#         color = polys[-1].get_facecolor()\n",
    "#         axarr[i].vlines(onp.nanmedian(samp_maxs), 0, 10, lw=1, color=color, alpha=1, linestyle='--')\n",
    "#     probs_true_max = n_alts_data[1]['probs_true'].max(axis=1)\n",
    "#     g = sns.kdeplot(probs_true_max, fill=True, ax=axarr[i], label=str(1), lw=3, )\n",
    "#     polys = [poly for poly in g.get_children() if type(poly) == mpl.collections.PolyCollection]\n",
    "#     color = polys[-1].get_facecolor()\n",
    "#     axarr[i].vlines(onp.nanmedian(probs_true_max), 0, 10, lw=2, color=color,alpha=1, )\n",
    "#     axarr[i].legend(title='Sample Rate')\n",
    "#     axarr[i].set_title(\"$N$ = {0}\".format(num_alts), fontsize=15)\n",
    "# fig.suptitle(\"Max. True Probability Across Choosers\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce283dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axarr = plt.subplots(2, 1, figsize=(15, 10), sharex=True, sharey=True)\n",
    "# for i, (num_alts, n_alts_data) in enumerate(n_alts_dict.items()):\n",
    "    \n",
    "#     probs_true = n_alts_data[1]['probs_true']\n",
    "#     true_massing = np.nansum(probs_true, axis=0)\n",
    "#     order = true_massing.argsort()[::-1]\n",
    "#     for sample_size, sample_size_data in n_alts_data.items():\n",
    "#         if sample_size == 1:\n",
    "#             continue\n",
    "            \n",
    "#         probs_samp_sparse = sample_size_data['probs_samp_sparse']\n",
    "#         sampled_massing = np.nansum(probs_samp_sparse, axis=0)\n",
    "#         massing_err = (true_massing - sampled_massing)\n",
    "#         z = sm.nonparametric.lowess(massing_err[order], true_massing[order], frac=1/20, it=6)\n",
    "#         axarr[i].plot(z[:,0], z[:,1], lw=1, alpha=0.4)\n",
    "#         axarr[i].scatter(true_massing[order], massing_err[order], marker='o', label=str(sample_size), alpha=0.5)\n",
    "\n",
    "#     axarr[i].axhline(y=0, color='k', linestyle='--', lw=0.5)\n",
    "\n",
    "#     axarr[i].legend(title='Sample Rate')\n",
    "#     axarr[i].set_ylabel('Error')\n",
    "#     axarr[i].set_xscale('log')\n",
    "#     axarr[i].set_yscale('symlog')\n",
    "#     axarr[i].set_title(\"$N$ = {0}\".format(num_alts), fontsize=15)\n",
    "\n",
    "# axarr[i].set_xlabel('True Probability Mass')\n",
    "\n",
    "# fig.suptitle(\"Probability Massing Error\", fontsize=20)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25348e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axarr = plt.subplots(2, 1, figsize=(15, 10), sharex=False)\n",
    "# for i, (num_alts, n_alts_data) in enumerate(n_alts_dict.items()):\n",
    "    \n",
    "#     probs_true = n_alts_data[1]['probs_true']\n",
    "#     true_massing = np.nansum(probs_true, axis=0) / probs_true.shape[0]\n",
    "#     order = true_massing.argsort()[::-1]\n",
    "\n",
    "#     axarr[i].plot(range(num_alts), true_massing[order], color='b', alpha=.5, label='True')\n",
    "\n",
    "#     for sample_size, sample_size_data in n_alts_data.items():\n",
    "#         if sample_size == 1:\n",
    "#             continue\n",
    "#         probs_samp_sparse = sample_size_data['probs_samp_sparse']\n",
    "#         samp_massing = np.nansum(probs_samp_sparse, axis=0) / probs_true.shape[0]\n",
    "#         axarr[i].plot(range(num_alts), samp_massing[order], label=sample_size, lw=0.5)\n",
    "\n",
    "#         axarr[i].legend(title='Sample Rate')\n",
    "#         axarr[i].set_title('', fontsize=15)\n",
    "#         axarr[i].set_ylabel('% Probability Mass')\n",
    "#         axarr[i].set_title(\"$N$ = {0}\".format(num_alts), fontsize=15)\n",
    "\n",
    "# axarr[i].set_xlabel('Alternative ID')\n",
    "\n",
    "# fig.suptitle(\"Probability Massing of Alts - Sorted by True Prob. Mass\", fontsize=20)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axarr = plt.subplots(2, 1, figsize=(15, 10), sharex=False)\n",
    "# for i, (num_alts, n_alts_data) in enumerate(n_alts_dict.items()):\n",
    "    \n",
    "#     probs_true = n_alts_data[1]['probs_true']\n",
    "#     true_massing = np.nansum(probs_true, axis=0) / probs_true.shape[0]\n",
    "#     order = true_massing.argsort()[::-1]\n",
    "\n",
    "#     axarr[i].plot(range(num_alts), true_massing[order], color='b', alpha=.5, label='True')\n",
    "\n",
    "#     for sample_size, sample_size_data in n_alts_data.items():\n",
    "#         if sample_size == 1:\n",
    "#             continue\n",
    "#         probs_samp_sparse = sample_size_data['probs_samp_sparse']\n",
    "#         samp_massing = np.nansum(probs_samp_sparse, axis=0) / probs_true.shape[0]\n",
    "#         axarr[i].plot(range(num_alts), samp_massing[order], label=sample_size, lw=0.5)\n",
    "\n",
    "#         axarr[i].legend(title='Sample Rate')\n",
    "#         axarr[i].set_title('', fontsize=15)\n",
    "#         axarr[i].set_ylabel('% Probability Mass')\n",
    "#         axarr[i].set_xlim(-1, 50)\n",
    "#         axarr[i].set_title(\"$N$ = {0}\".format(num_alts), fontsize=15)\n",
    "\n",
    "# axarr[i].set_xlabel('Alternative ID')\n",
    "\n",
    "# fig.suptitle(\"Probability Massing of Top 50 Alts - Sorted by True Prob. Mass\", fontsize=20)\n",
    "# fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:proba]",
   "language": "python",
   "name": "conda-env-proba-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

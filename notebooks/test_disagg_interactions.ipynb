{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as onp\n",
    "from jax import numpy as np\n",
    "from functools import partial\n",
    "from jax.ops import segment_sum\n",
    "from jax import random, grad, jit, vmap, remat, lax\n",
    "\n",
    "def softmax(utilities):\n",
    "    exp_utility = np.exp(utilities)\n",
    "    sum_expu_across_submodels = np.sum(exp_utility, axis=1, keepdims=True)\n",
    "    proba = exp_utility / sum_expu_across_submodels\n",
    "    return proba\n",
    "\n",
    "def mse(target, predicted):\n",
    "    error = target - predicted\n",
    "    squared_error = error**2\n",
    "    return np.mean(squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 187)\n"
     ]
    }
   ],
   "source": [
    "target = onp.load('target.npy')\n",
    "x = onp.load('x.npy')\n",
    "print(x.shape)\n",
    "w = np.array([[ 0.00304216,  0.01455319, -0.0026763 ,  0.02046709,\n",
    "               0.00563778, -0.00192821, -0.01059241,  0.00204556,\n",
    "               0.0079378 ,  0.00027923,  0.01584745]])\n",
    "\n",
    "# 10k alternatives\n",
    "x = np.tile(x, 54)\n",
    "target = np.tile(target, 54)\n",
    "\n",
    "chooser_incomes = onp.random.normal(60000, 15000, 100000) ## 100k chooser incomes\n",
    "chooser_incomes = chooser_incomes / 100000\n",
    "chooser_incomes_reshaped = chooser_incomes.reshape((40, 2500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 10098)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "@remat\n",
    "def income_interaction(income, x, idx_alt_income=1, w=w):\n",
    "    \"\"\"For a single chooser, interact their income with\n",
    "       the alternatives' income-related attribute (e.g. mean income).\n",
    "       Then calculate probabilities across alternatives for this\n",
    "       single chooser. Other interactions, or interaction types,\n",
    "       could be added here-  e.g. enforcement of budget constaints.\n",
    "       \n",
    "       Parameters\n",
    "       ----------\n",
    "       income : float\n",
    "           Scalar income value for the single chooser.\n",
    "       x : np.array\n",
    "           Array of alternatives' explanatory variables.  Should be of\n",
    "           shape (num_expvars, num_alts)\n",
    "       idx_alt_income : int\n",
    "           Index location of the explanatory variable in x that pertains\n",
    "           to income.\n",
    "        w : np.array\n",
    "            Weights (parameter values).  Of shape (1, num_expvars)\n",
    "       \"\"\"\n",
    "    income_interacted = x[idx_alt_income] * income\n",
    "    x2 = x.at[idx_alt_income].set(income_interacted)\n",
    "    \n",
    "    logits = np.dot(w, x2)\n",
    "    probas = softmax(logits)\n",
    "    probas = probas.flatten()\n",
    "    return probas\n",
    "\n",
    "#Partialed, 1-argument form of the income_interaction func\n",
    "income_interaction2 = partial(income_interaction, x=x, idx_alt_income=1, w=w)\n",
    "\n",
    "def loss_disagg(weights):\n",
    "    \"\"\"VMAP the income interaction function over all choosers' incomes\"\"\"\n",
    "    income_interaction3 = partial(income_interaction, x=x, idx_alt_income=1, w=weights)\n",
    "    probas_all = vmap(income_interaction3)(chooser_incomes)\n",
    "    proba_sum = np.sum(probas_all, axis=0)\n",
    "    return mse(proba_sum, target)\n",
    "\n",
    "def loss_disagg_lax(weights):\n",
    "    \"\"\"lax.map over batches of choosers-  lower memory version of loss_disagg\"\"\"\n",
    "    income_interaction3 = partial(income_interaction, x=x, idx_alt_income=1, w=weights)\n",
    "    ## Map over batches of choosers, VMAP each batch of choosers. #Reshaped choosers has dim == num_batches\n",
    "    probas_all = lax.map(vmap(income_interaction3), chooser_incomes_reshaped)\n",
    "\n",
    "    ## Reshape output to remove the batch dimension\n",
    "    num_alts = x.shape[1]\n",
    "    num_total_choosers = chooser_incomes_reshaped.size\n",
    "    probas_all = probas_all.reshape((num_total_choosers, num_alts))\n",
    "    \n",
    "    ## Sum probas for each alternative\n",
    "    proba_sum = np.sum(probas_all, axis=0)\n",
    "    return mse(proba_sum, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probas for single chooser\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([9.9656630e-05, 9.8727876e-05, 9.9612160e-05, ...,\n",
       "             9.2831062e-05, 1.1771860e-04, 9.2662689e-05], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('probas for single chooser')\n",
    "income_interaction2(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_disagg\n",
      "0.5063130855560303\n"
     ]
    }
   ],
   "source": [
    "print('loss_disagg')\n",
    "start_time = time.time()\n",
    "\n",
    "loss_disagg(w)\n",
    "\n",
    "end_time = time.time()\n",
    "time_elapsed = end_time - start_time\n",
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_disagg_lax\n",
      "0.4029693603515625\n"
     ]
    }
   ],
   "source": [
    "print('loss_disagg_lax')\n",
    "start_time = time.time()\n",
    "\n",
    "loss_disagg_lax(w)\n",
    "\n",
    "end_time = time.time()\n",
    "time_elapsed = end_time - start_time\n",
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad of loss\n",
      "[[ 0.12902279 -0.3715989  -0.9149651   4.1221437   2.4685009   0.35714096\n",
      "  -1.8347561   0.13082723  3.187939   -0.6747903  -1.4099519 ]]\n",
      "77.58303189277649\n"
     ]
    }
   ],
   "source": [
    "print('grad of loss')\n",
    "loss_disagg_lax_grad = grad(loss_disagg_lax)\n",
    "print(loss_disagg_lax_grad(w))\n",
    "\n",
    "end_time = time.time()\n",
    "time_elapsed = end_time - start_time\n",
    "print(time_elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:proba]",
   "language": "python",
   "name": "conda-env-proba-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
